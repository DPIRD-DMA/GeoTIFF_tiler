{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d87967",
   "metadata": {},
   "source": [
    "This script will create a tiled version of a raster dataset, it is expected that the input imagery is either one large raster or multible edge matched rasters of the same resolution. You are able to define the size of the tiles and the amount of overlap between tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74725eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import math\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocess import Pool,cpu_count\n",
    "%matplotlib inline\n",
    "\n",
    "from osgeo import gdal,osr\n",
    "import geopandas as gpd\n",
    "from shapely import geometry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size_px = [500,500] #x,y\n",
    "tile_oxerlap_px = 150\n",
    "\n",
    "geotiff_folder = '/data/Road extraction/test area 10/test area 10'\n",
    "output_folder = '/data/Road extraction/test area 10/tiles'\n",
    "#if you want to use all of your rasters set the below value to None\n",
    "valid_rasters_csv = ''\n",
    "    \n",
    "input_file_ext = '.tif'\n",
    "output_compression = 'JPEG'  #use JPEG for images and LZW for raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you want the output tiles to be nested into row folders?\n",
    "output_to_row_folders = True\n",
    "# do you want to append a string to every tile?\n",
    "raster_name_append = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05380c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump tile setting a a json file into output location\n",
    "parent_dir = os.path.dirname(output_folder)\n",
    "settings_file_path = os.path.join(parent_dir,'tiling_settings.json')\n",
    "settings = {'tile_size_px':tile_size_px,\n",
    "           'tile_oxerlap_px':tile_oxerlap_px,\n",
    "           'raster_name_append':raster_name_append,\n",
    "           'tile_format':'.tif'}\n",
    "with open(settings_file_path, 'w') as fp:\n",
    "    json.dump(settings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "os.path.isdir(geotiff_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba747de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search folder and all sub folders for 'input_file_ext' files\n",
    "geo_tiff_list = []\n",
    "for root, dirs, files in os.walk(geotiff_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(input_file_ext):\n",
    "            geo_tiff_list.append(os.path.join(root, file))\n",
    "            \n",
    "print('We found ',len(geo_tiff_list),input_file_ext,'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648aadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to filter our input raster use this\n",
    "if valid_rasters_csv:\n",
    "    valid_raster_df = pd.read_csv(valid_rasters_csv)\n",
    "    print(valid_raster_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the valid raster names into a set so the lookup if much faster\n",
    "if valid_rasters_csv:\n",
    "    valid_raster_names = set(valid_raster_df.name.tolist())\n",
    "    valid_raster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "if valid_rasters_csv:\n",
    "    short_list = []\n",
    "    for tif in tqdm(geo_tiff_list):\n",
    "    #     my csv file does not have the file extension so we are stripping out the '.tif' to find a match\n",
    "        file_name = os.path.basename(tif)#.replace('.tif','') \n",
    "    #     check if the current raster is in the list, if so add it to the clean list\n",
    "        if file_name in valid_raster_names:\n",
    "            short_list.append(tif)\n",
    "    # reset the full list to the clean list        \n",
    "    geo_tiff_list = short_list\n",
    "    print(len(geo_tiff_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds(tif_path):\n",
    "#     open file\n",
    "    data = gdal.Open(tif_path)\n",
    "#     grab bounds\n",
    "    geoTransform = data.GetGeoTransform()\n",
    "    left = geoTransform[0]\n",
    "    top = geoTransform[3]\n",
    "    right = left + geoTransform[1] * data.RasterXSize\n",
    "    bottom = top + geoTransform[5] * data.RasterYSize\n",
    "#     build dict to file bounds\n",
    "    geo_tiff_bounds_dict = {'top':top,'left':left,'bottom':bottom,'right':right,'tif_path':tif_path}\n",
    "    return geo_tiff_bounds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the above function by returning the bounds of the first raster\n",
    "geo_tiff_bounds = get_bounds(geo_tiff_list[0])\n",
    "geo_tiff_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multiprocessing to extract raster bounds\n",
    "with Pool() as pool:\n",
    "    geo_tiff_bounds = list(tqdm(pool.imap(get_bounds, geo_tiff_list), total=len(geo_tiff_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new array with only bounds to extract full raster extents\n",
    "pure_bounds = []\n",
    "for geo_tif_bounds in geo_tiff_bounds:\n",
    "    pure_bounds.append([geo_tif_bounds['top'],geo_tif_bounds['left'],geo_tif_bounds['bottom'],geo_tif_bounds['right']])\n",
    "# convert into numpy array\n",
    "pure_bounds_np = np.array(pure_bounds)\n",
    "# grab max extents\n",
    "bound_y_max = float(pure_bounds_np[:,0].max()) #top\n",
    "bound_x_min = float(pure_bounds_np[:,1].min()) #left\n",
    "bound_y_min = float(pure_bounds_np[:,2].min()) #bottom\n",
    "bound_x_max = float(pure_bounds_np[:,3].max()) #right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b48823",
   "metadata": {},
   "outputs": [],
   "source": [
    "'top',bound_y_max,'left',bound_x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e211e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open one image to get the pixel size, this is necessary to know how to cut the rasters\n",
    "test_raster = gdal.Open(geo_tiff_list[0])\n",
    "test_raster_gt =test_raster.GetGeoTransform()\n",
    "pixel_size_x = test_raster_gt[1]\n",
    "pixel_size_y = test_raster_gt[5]\n",
    "print(pixel_size_x,pixel_size_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = osr.SpatialReference(wkt=test_raster.GetProjection())\n",
    "crs = 'EPSG:'+proj.GetAttrValue('AUTHORITY',1)\n",
    "crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the geographical distance in each direction each tile must be from the last tile\n",
    "x_move = pixel_size_x*(tile_size_px[0]-tile_oxerlap_px)\n",
    "y_move = pixel_size_y*(tile_size_px[1]-tile_oxerlap_px)\n",
    "print(x_move,y_move)\n",
    "\n",
    "# calculate the geographical size of each tile\n",
    "x_tile_size = pixel_size_x*tile_size_px[0]\n",
    "y_tile_size = pixel_size_y*tile_size_px[1]\n",
    "print(x_tile_size,y_tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of cols so we can avoid using while loops\n",
    "number_of_cols = math.ceil(abs((bound_x_max-bound_x_min)/x_move))\n",
    "number_of_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d020a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of rows so we can avoid using while loops\n",
    "number_of_rows = math.ceil(abs((bound_y_max-bound_y_min)/y_move))\n",
    "number_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f016525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will return a list of geotiffs which intersect \n",
    "def intersect_tile_with_geotiffs(tile_dict,geo_tiff_bounds):\n",
    "#     setup set to collect results in, a set is used to avoid duplicates\n",
    "    intersecting_geotiffs = set()\n",
    "#     loop over each geotiff\n",
    "    for geo_bounds in geo_tiff_bounds:\n",
    "#         check is tile top or bottom is inside geotiff\n",
    "        if (geo_bounds['top'] > tile_dict['top'] > geo_bounds['bottom'] or \n",
    "            geo_bounds['top'] > tile_dict['bottom'] > geo_bounds['bottom']):\n",
    "#         check if left or right are inside a geotiff\n",
    "            if geo_bounds['right'] > tile_dict['left'] > geo_bounds['left']:\n",
    "                intersecting_geotiffs.add(geo_bounds['tif_path'])\n",
    "            if geo_bounds['right'] > tile_dict['right'] > geo_bounds['left']:\n",
    "                intersecting_geotiffs.add(geo_bounds['tif_path'])\n",
    "    return intersecting_geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will take tile bounds and only export them if they fall within a geotiff\n",
    "# this is called row by row by pool below\n",
    "def make_polygons(row):\n",
    "    tile_polygon_list = []\n",
    "    tile_top = bound_y_max + y_move*row\n",
    "    tile_bottom = tile_top + y_tile_size\n",
    "    tile_left = bound_x_min\n",
    "\n",
    "    for col in range(0,number_of_cols):\n",
    "        tile_left = bound_x_min + col*x_move\n",
    "        tile_right = tile_left + x_tile_size\n",
    "        tile_dict = {'top':tile_top,'left':tile_left,'bottom':tile_bottom,'right':tile_right}\n",
    "        tile_list = np.array([tile_top,tile_left,tile_bottom,tile_right])\n",
    "#         check if valid tile\n",
    "        intersect = intersect_tile_with_geotiffs(tile_dict,geo_tiff_bounds)\n",
    "        raster_name = raster_name_append+str(row)+'_'+str(col)+'.tif'\n",
    "        if len(intersect) > 0:\n",
    "            polygon = {'geometry':geometry.Polygon([[tile_left, tile_top], [tile_right, tile_top], [tile_right, tile_bottom], [tile_left, tile_bottom]]),\n",
    "                      'intersect':intersect, 'row':row, 'col':col, 'name':raster_name}\n",
    "            tile_polygon_list.append(polygon)\n",
    "    return tile_polygon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocess making polygons\n",
    "with Pool() as pool:\n",
    "    tile_polygon_list = list(tqdm(pool.imap(make_polygons, range(0,number_of_rows)), total=len(range(0,number_of_rows))))\n",
    "\n",
    "# this is returned as a list of list so it must be flattened\n",
    "tile_polygon_list = list(np.concatenate(tile_polygon_list).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46639a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#  convert into geodataframe\n",
    "polygon_tiles_gpd = gpd.GeoDataFrame(tile_polygon_list,geometry='geometry',crs=crs)\n",
    "del polygon_tiles_gpd['intersect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd40f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_tiles_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e015da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot up a bunch of polygons\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "polygon_tiles_gpd.head(10000).plot(column='col', ax=ax, legend=True,cax=cax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a small number of polygon bounds\n",
    "polygon_tiles_gpd.head(10).boundary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_export_loc = os.path.join(os.path.dirname(output_folder),'output_no_overlap.gpkg')\n",
    "polygon_export_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_tiles_gpd.to_file(polygon_export_loc, driver=\"GPKG\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of which tiles are within which geotiffs\n",
    "def intersector(geo_tiff):\n",
    "    tiles_inside_geo_tiff = []\n",
    "#     loop over each tile and check if the geotiff is the the intersect list\n",
    "    for tile in tile_polygon_list:\n",
    "        if geo_tiff in tile['intersect']:\n",
    "#             count this so we know if the tile will be incomplete or not\n",
    "            incomplete = len(tile['intersect'])>1\n",
    "#             build dict with geom the current row and col for naming\n",
    "            tiles_inside_geo_tiff.append({'geometry':tile['geometry'],'row':tile['row'],'col':tile['col'],'name':tile['name'],'incomplete':incomplete})\n",
    "    return([geo_tiff,tiles_inside_geo_tiff])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803304c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool() as pool:\n",
    "    geo_tiff_with_tiles = list(tqdm(pool.imap(intersector, geo_tiff_list), total=len(geo_tiff_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06b782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut tiles from rasters\n",
    "def cut_tiles(geotiff):\n",
    "#     grab path to to file and open it\n",
    "    geotiff_open = gdal.Open(geotiff[0])\n",
    "#     grab the filename and strip the extension\n",
    "    geo_tiff_filename = os.path.basename(geotiff[0]).replace(input_file_ext,'')\n",
    "    incomplete_tile_list = []\n",
    "    for tile in geotiff[1]:\n",
    "        tile_geometry = tile['geometry']\n",
    "#         shapely bounds returns \"minx, miny, maxx, maxy\" but we need minx, maxy, maxx, miny\n",
    "        top = list(tile_geometry.bounds)[3]\n",
    "        bottom = list(tile_geometry.bounds)[1]\n",
    "        left = list(tile_geometry.bounds)[0]\n",
    "        right =list(tile_geometry.bounds)[2]\n",
    "        \n",
    "#         make row folder path\n",
    "        if output_to_row_folders:\n",
    "            output_row_folder = os.path.join(output_folder,str(tile['row']))\n",
    "            Path(output_row_folder).mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "            output_row_folder = output_folder\n",
    "#       make row folder if necessary\n",
    "        \n",
    "        export_file_name = str(tile['name'])#str(tile['row'])+'_'+str(tile['col'])+'.tif'\n",
    "        \n",
    "#         check if tile is incomplete if so append the getiff name so that it is unique\n",
    "        if tile['incomplete']:\n",
    "            append_name = '-'+geo_tiff_filename+'_incomplete.tif'\n",
    "            export_file_name = export_file_name.replace('.tif',append_name)\n",
    "#             add tile to list so we dont need to refind them to compile incomplete tiles\n",
    "            export_file_path = os.path.join(output_row_folder,export_file_name)\n",
    "            incomplete_tile_list.append(export_file_path)\n",
    "        else:\n",
    "            export_file_path = os.path.join(output_row_folder,export_file_name)\n",
    "        \n",
    "#         check if already done\n",
    "        if not os.path.isfile(export_file_path):\n",
    "\n",
    "    #     clip the data\n",
    "    #         make a string of tile dims to pass as a command line arg, this is kinda of hacky, would like a better option\n",
    "            tile_clip_string = str(left) +' '+str(top) +' '+str(right) +' '+str(bottom)\n",
    "\n",
    "            translate_options = gdal.TranslateOptions(gdal.ParseCommandLine(\"-projwin \"+tile_clip_string)\n",
    "                                                     ,creationOptions=['COMPRESS='+output_compression])\n",
    "\n",
    "            tile_clip = gdal.Translate(export_file_path, geotiff_open, options = translate_options)\n",
    "    #     close the tile\n",
    "            tile_clip = None\n",
    "    return incomplete_tile_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to slip a list into n chunks of roughly the same size\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to cpu_count() unless you are running out of RAM in which case decrease it\n",
    "concurrent_threads = cpu_count()\n",
    "concurrent_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ebdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_count = 0\n",
    "for raster,tiles in geo_tiff_with_tiles:\n",
    "    tile_count+=len(tiles)\n",
    "average_tile_count = round(tile_count/len(geo_tiff_with_tiles))\n",
    "average_tile_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc498ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have more cores than rasters and more cores than average tile count then give every core a copy of the same raster to work on\n",
    "if concurrent_threads > len(geo_tiff_with_tiles) and concurrent_threads < average_tile_count:\n",
    "    print('You have more threads than rasters so we each thread will get the same raster')\n",
    "    incomplete_tile_list = []\n",
    "\n",
    "    for raster,tiles in tqdm(geo_tiff_with_tiles):\n",
    "        geo_tiff_with_tile_list = []\n",
    "\n",
    "        for tile_split in split(tiles,concurrent_threads):\n",
    "            geo_tiff_with_tile_list.append([raster,tile_split])\n",
    "\n",
    "        pool = Pool(concurrent_threads)\n",
    "        with pool:\n",
    "            one_raster_incomplete_tile_list = list(pool.imap(cut_tiles,geo_tiff_with_tile_list))\n",
    "\n",
    "        incomplete_tile_list.append(np.concatenate(one_raster_incomplete_tile_list))\n",
    "    \n",
    "else:\n",
    "    print('you have more rasters than threads so each thread will get its own raster')\n",
    "    pool = Pool()\n",
    "    with pool:\n",
    "        incomplete_tile_list = list(tqdm(pool.imap(cut_tiles,geo_tiff_with_tiles), total=len(geo_tiff_with_tiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca407735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the pool above returns all the incomplete tiles as a list of list, we need a flat list\n",
    "flat_incomplete_tile_list = np.concatenate(incomplete_tile_list).ravel()\n",
    "print(len(flat_incomplete_tile_list),'incomplete tiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the flat list make a new list with just rows and cols to filter by\n",
    "incomplete_tile_file_names = []\n",
    "for incomplete_tile in flat_incomplete_tile_list:\n",
    "    incomplete_tile_file_names.append(os.path.basename(incomplete_tile).split('-')[0].replace(raster_name_append,''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19367e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe with paths and row/cols\n",
    "incomplete_tile_df = pd.DataFrame(\n",
    "    {'incomplete_tiles': flat_incomplete_tile_list,\n",
    "     'row_col': incomplete_tile_file_names\n",
    "    })\n",
    "\n",
    "unique_tiles_list = incomplete_tile_df.row_col.unique()\n",
    "\n",
    "incomplete_tile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13279c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_tile_df['incomplete_tiles'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da67c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy gdal tool to merge files\n",
    "def merge_tiles(merge_imgs, output_path):\n",
    "    merge_command = ['gdal_merge.py', '-o', output_path, '-quiet', '-co','COMPRESS='+output_compression]\n",
    "    for name in merge_imgs:\n",
    "        merge_command.append(name)\n",
    "    subprocess.run(merge_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90092fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_incomplete_tile(unique_tiles):\n",
    "#     filter the dataframe down to only one row and col\n",
    "    df_filt = incomplete_tile_df[incomplete_tile_df['row_col']==unique_tiles]\n",
    "#     get paths as list\n",
    "    combine_these = df_filt['incomplete_tiles'].tolist()\n",
    "#     get export name by removing the geotiff names from end\n",
    "    export_file_name = os.path.basename(combine_these[0]).split('-')[0]+'.tif'\n",
    "#     grab the folder from the first tile\n",
    "    export_dir_path = os.path.dirname(combine_these[0])\n",
    "#     build full export path\n",
    "    export_full_path = os.path.join(export_dir_path,export_file_name)\n",
    "#     use gdal gdal_merge.py to merge the tiles\n",
    "    merge_tiles(combine_these,export_full_path)\n",
    "#     remove the incomplete tiles and msk files\n",
    "    for incomplete_tile in combine_these:\n",
    "        try:\n",
    "            os.remove(incomplete_tile)\n",
    "        except:\n",
    "            print('could not remove')\n",
    "        if os.path.isfile(incomplete_tile+'.msk'):\n",
    "            try:\n",
    "                os.remove(incomplete_tile+'.msk')\n",
    "            except:\n",
    "                print('could not remove')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "with pool:\n",
    "    list(tqdm(pool.imap(join_incomplete_tile,unique_tiles_list), total=len(unique_tiles_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a039ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want you can validate the output of the above code with the below cells, this is probibly not needed in most cases\n",
    "# from https://github.com/fastai/fastai/blob/master/fastai/vision/utils.py\n",
    "from PIL import Image\n",
    " \n",
    "def verify_image(fn):\n",
    "    try:\n",
    "        im = Image.open(fn)\n",
    "        im.draft(im.mode, (32,32))\n",
    "        im.load()\n",
    "        return True\n",
    "    except: return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles = []\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.tif'):\n",
    "            all_tiles.append(os.path.join(root, file))\n",
    "len(all_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool():\n",
    "    failed_tiles = list(tqdm(Pool().imap(verify_image,all_tiles), total=len(all_tiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(failed_tiles):\n",
    "    if not i:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
